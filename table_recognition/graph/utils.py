import cv2
import matplotlib.pyplot as plt
import networkx as nx
import numpy as np
import torch
import os
from typing import Tuple

from torch_geometric.utils import to_networkx
from torch_geometric.data import Data
from torchvision.ops import RoIAlign
from operator import itemgetter


def coords_string_to_tuple_list(coords_string: str) -> [(int, int)]:
    """
    A function that transforms string with coordinates of 2D points
    to list of tuples.

    Example of 2D coordinate string:
        "1,1 2,2 3,3 4,4 ..."

    Example of list of tuples:
         [(1,1), (2,2), (3,3), (4,4), ...]

    :type coords_string:  String
    :param coords_string: String with coordinates of 2D points
    :return:              A list of int tuples
    """

    str_2d_points = coords_string.split(" ")
    return [(int(str_2d_point.split(",")[0]), int(str_2d_point.split(",")[1]))
            for str_2d_point in str_2d_points]


def tuple_list_to_coords_string(tuple_list: [(int, int)]) -> str:
    """
    Inverse function to coords_string_to_tuple_list() that transforms a list
    of integer tuples to string.

    Example of integer tuples:
        [(1,1), (2,2), (3,3), (4,4), ...]

    Example of the output string:
        "1,1 2,2 3,3 4,4 ..."

    :type tuple_list:   List of integer tuples
    :param tuple_list:  List of integer tuples
    :return:            String that contains the transformed list of integer tuples
    """

    return " ".join([str(number_fst) + "," + str(number_nd)
                     for number_fst, number_nd in tuple_list])


def get_multiple_values_from_dict(dict: {}, keys: []) -> []:
    """
    Returns multiple values from dictionary with a single call.

    :param dict:  A dictionary that contains the wanted values.
    :param keys:  Keys that should be used to find the values in
                  the dictionary.
    :return:      A list with the wanted values.
    """
    if not keys:
        return []

    values = itemgetter(*keys)(dict)

    if type(values) is tuple:
        return list(values)
    else:
        return [values]


def range_wrapper(start_value: int, end_value: int) -> [int]:
    """
    Wrapper around builtin function range(). The function returns
    start_value when start_value == end_value.

    :param start_value: Start value for range()
    :param end_value:   End value for range()
    :return:            List of integers generated by range()
    """
    return list(range(start_value, end_value)) + [end_value]


def visualize_graph(data: Data) -> None:
    us = data.edge_index[0]
    vs = data.edge_index[1]
    edges = [(int(u), int(v)) for u, v in zip(us, vs)]

    G = nx.Graph()
    for node_idx, node_attributes in enumerate(data.visualize_position):
        G.add_node(node_idx, position=(float(node_attributes[0]), float(node_attributes[1])))

    position = nx.get_node_attributes(G, 'position')

    for u, v in edges:
        G.add_edge(u, v)

    nx.draw(G, position, with_labels=True)
    plt.show()
    return None


def visualize_model_output(data, out_nodes, out_edges):
    G = nx.Graph()
    us = data.edge_index[0]
    vs = data.edge_index[1]
    color_edges = {
        0: "red",  # cell
        1: "blue",  # horizontal
        2: "orange",  # vertical
        3: "purple"
    }
    edges = [(int(u), int(v), color_edges[t]) for u, v, t in zip(us, vs, out_edges.numpy())]

    for node_idx, node_attributes in enumerate(data.node_image_position):
        G.add_node(node_idx, position=(float(node_attributes[0]), float(node_attributes[1])), type=out_nodes[node_idx])

    for u, v, t in edges:
        G.add_edge(u, v, type=t)

    color_map_nodes = ["blue" if G.nodes[node_idx] == 1 else "red" for node_idx in G]
    color_map_edges = [G[u][v]["type"] for u, v in G.edges()]

    position = nx.get_node_attributes(G, 'position')
    nx.draw(G, position, node_color=color_map_nodes, edge_color=color_map_edges, with_labels=True)
    plt.show()
    # print(G.nodes(data=True))


def visualize_output_image(data, out_nodes, out_edges, visualize_path):
    data.cpu()
    out_nodes.cpu()
    out_edges.cpu()
    
    us = data.edge_index[0]
    vs = data.edge_index[1]
    color_edges = {
        0: "red",  # cell
        1: "blue",  # horizontal
        2: "orange",  # vertical
        3: "purple"
    }
    edges = [(int(u), int(v), color_edges[t]) for u, v, t in zip(us, vs, out_edges.numpy())]

    img = cv2.imread(data.img_path[0])
    for node_idx, node_attributes in enumerate(data.node_image_position):
        cv2.circle(img, (int(node_attributes[0]), int(node_attributes[1])), radius=10, color=(255, 255, 255),
                   thickness=-1)

    for u, v, c in edges:
        position_u = (int(data.node_image_position[u][0]), int(data.node_image_position[u][1]))
        position_v = (int(data.node_image_position[v][0]), int(data.node_image_position[v][1]))
        color_to_rgb = {
            "red": (0, 0, 255),
            "blue": (255, 0, 0),
            "orange": (0, 140, 255),
            "purple": (128, 0, 128)
        }
        cv2.line(img, position_u, position_v, color=color_to_rgb[c], thickness=3)

    img_path = os.path.join(visualize_path, data.img_path[0].split("/")[-1])
    cv2.imwrite(img_path, img)
    # cv2.imshow("visualize output", img)
    # cv2.waitKey(0)


def visualize_input_image(data, visualize_path):
    us = data.edge_index[0]
    vs = data.edge_index[1]
    color_edges = {
        0: "red",  # cell
        1: "blue",  # horizontal
        2: "orange",  # vertical
        3: "purple"
    }
    edge_output_attr = None
    edges = [(int(u), int(v), color_edges[t]) for u, v, t in
             zip(us, vs, torch.argmax(data.edge_output_attr, dim=1).numpy())]

    img = cv2.imread(data.img_path[0])
    for node_idx, node_attributes in enumerate(data.node_image_position):
        cv2.circle(img, (int(node_attributes[0]), int(node_attributes[1])), radius=10, color=(255, 255, 255),
                   thickness=-1)

    for u, v, c in edges:
        position_u = (int(data.node_image_position[u][0]), int(data.node_image_position[u][1]))
        position_v = (int(data.node_image_position[v][0]), int(data.node_image_position[v][1]))
        color_to_rgb = {
            "red": (0, 0, 255),
            "blue": (255, 0, 0),
            "orange": (0, 140, 255),
            "purple": (128, 0, 128)
        }
        cv2.line(img, position_u, position_v, color=color_to_rgb[c], thickness=3)

    img_path = os.path.join(visualize_path, data.img_path[0].split("/")[-1])
    cv2.imwrite(img_path, img)


def numpy_img_to_pytorch_img(img: np.array) -> torch.Tensor:
    return torch.tensor([img.numpy().transpose(2, 1, 0)]).type('torch.FloatTensor')


def pytorch_img_to_numpy_img(img: torch.Tensor) -> np.array:
    return img.numpy().transpose(2, 1, 0).astype(np.uint8)


def roi_align_single_image(img: np.array, dim: Tuple[int, int]) -> torch.Tensor:
    h, w, c = img.shape
    roi_align = RoIAlign(dim, 1.0, -1)
    coords = torch.cat((torch.Tensor([0]), torch.Tensor([0, 0, h, w]))).view(1, 5)

    img = img.numpy().transpose(2, 1, 0)
    img = np.array([img])
    img = torch.from_numpy(img)

    new_img = roi_align(img.type('torch.FloatTensor'), coords)

    #new_img = new_img.numpy().transpose(3, 2, 1, 0)[:, :, :, 0]

    return new_img[0]

